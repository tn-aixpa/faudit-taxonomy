{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdd79a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/4TB/elisa/AIxPA/env_aixpa/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bertopic import BERTopic\n",
    "from datetime import datetime\n",
    "from umap import UMAP\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15bcc45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: ./TopicModelling_TitoloDescrizione_20251031-1419_100topics/\n",
      "Totale documenti (titolo azione + descrizione) utilizzati per l'analisi: 17024\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SEZIONE 1: Preparazione dati e parametri\n",
    "# -----------------------------------------------------------------------------\n",
    "# Questa sezione del notebook:\n",
    "# 1) Imposta i parametri di input per l'analisi (tipo di dati testuali da utilizzare (nell'esempio Titolo e descrizione) e numero di categorie (nell'esempio 100 categorie)).\n",
    "# 2) Carica il dataset delle azioni da CSV.\n",
    "# 3) Crea una cartella di output con timestamp per salvare i risultati in modo univoco.\n",
    "# 4) Filtra le righe con il campo 'descrizione' non vuoto.\n",
    "# 5) Costruisce una nuova colonna testuale 'text' combinando 'titolo' e 'descrizione'.\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# 1)--- Inputs ---\n",
    "TYPE_OF_ANALYSIS = \"TopicModelling_TitoloDescrizione_\"  # in questa analisi usiamo sia titolo che descrizione. \n",
    "                                          # È possibile aggiungere altri campi, ad es. \"obiettivi\".\n",
    "N_TOPICS = 100  # numero di topic/categorie che il modello deve trovare; regolarlo in base alla granularità desiderata.\n",
    "\n",
    "# 2) --- Caricamento dati ---\n",
    "df = pd.read_csv(\"./FT/azioni.csv\") # aggiustare il percorso del file CSV se necessario\n",
    "\n",
    "# 3) \n",
    "# --- Timestamp per cartella risultati (es. 20251030-1423) ---\n",
    "stamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "\n",
    "# --- Nome cartella ---\n",
    "folder_name = f\"{stamp}{TYPE_OF_ANALYSIS}n{N_TOPICS}\"\n",
    "\n",
    "# --- Creazione directory dei risultati ---\n",
    "\n",
    "mydir= './'+TYPE_OF_ANALYSIS+stamp + '_'+ str(N_TOPICS)+'topics/' # nel github per comodità la cartella è chiamata semplicemente \"Results\"\n",
    "\n",
    "\n",
    "os.mkdir(mydir)\n",
    "print(\"Created:\", mydir)\n",
    "\n",
    "# 4) --- Filtro e costruzione ---\n",
    "# Mantiene solo le righe con 'descrizione' non nulla\n",
    "df_filtered = df.dropna(subset=['descrizione']).copy()\n",
    "\n",
    "# 5) --- Filtro e costruzione ---\n",
    "# Crea la colonna 'text' combinando 'titolo' e 'descrizione' (robusto a NaN/whitespace)\n",
    "df_filtered['text'] = (\n",
    "    'Titolo: '\n",
    "    + df_filtered['titolo'].fillna('').astype(str).str.strip()\n",
    "    + '; Descrizione: '\n",
    "    + df_filtered['descrizione'].astype(str).str.strip()\n",
    ")\n",
    "\n",
    "print(\"Totale documenti (titolo azione + descrizione) utilizzati per l'analisi:\", len(df_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5091323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titolo : Area Community care : Carta giovani ; Descrizione : ' tessera nominativa gratuita permette usufruire sconti , servizi agevolazioni presso esercizi cittа aderito all'iniziativa espongono vetrofania Perugia Corciano Torgiano Carta Giovani .\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SEZIONE 2: Pulizia del testo (italiano) – mantiene la punteggiatura\n",
    "# -----------------------------------------------------------------------------\n",
    "# Questa sezione del notebook:\n",
    "# - Tokenizza il testo con NLTK `word_tokenize` (mantiene la punteggiatura).\n",
    "# - Rimuove le stopword italiane di NLTK (confronto case-insensitive).\n",
    "# - Restituisce una lista di stringhe pulite da usare, ad esempio, con BERTopic.\n",
    "# Nota: non forza il lowercase dell’output e non rimuove la punteggiatura.\n",
    "# =============================================================================\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "STOP_WORDS = set(stopwords.words('italian'))\n",
    "\n",
    "def drop_stopwords(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    return \" \".join(w for w in tokens if w.lower() not in STOP_WORDS)\n",
    "\n",
    "# Applica alla colonna e ottiene una lista\n",
    "docs_unique = df_filtered['text'].fillna('').map(drop_stopwords).tolist()\n",
    "\n",
    "print(docs_unique[10])  # esempio di documento pulito\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59e0acc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 14:23:32,979 - BERTopic - Embedding - Transforming documents to embeddings.\n",
      "Batches: 100%|██████████| 532/532 [04:08<00:00,  2.14it/s]\n",
      "2025-10-31 14:27:44,602 - BERTopic - Embedding - Completed ✓\n",
      "2025-10-31 14:27:44,603 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-10-31 14:27:57,960 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-10-31 14:27:57,962 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-10-31 14:27:59,817 - BERTopic - Cluster - Completed ✓\n",
      "2025-10-31 14:27:59,818 - BERTopic - Representation - Extracting topics using c-TF-IDF for topic reduction.\n",
      "2025-10-31 14:28:00,511 - BERTopic - Representation - Completed ✓\n",
      "2025-10-31 14:28:00,513 - BERTopic - Topic reduction - Reducing number of topics\n",
      "2025-10-31 14:28:00,567 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2025-10-31 14:28:01,107 - BERTopic - Representation - Completed ✓\n",
      "2025-10-31 14:28:01,110 - BERTopic - Topic reduction - Reduced number of topics from 274 to 100\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SEZIONE 3: creazione del modello con BERTopic e riduzione dimensionale al numero di categorie desiderate\n",
    "# -----------------------------------------------------------------------------\n",
    "# Questa sezione del notebook:\n",
    "# - Configura UMAP per ridurre la dimensionalità delle embedding testuali.\n",
    "# - Inizializza BERTopic per lingua italiana con i parametri dell’analisi.\n",
    "# - Addestra il modello sui documenti e restituisce l’assegnazione dei topic.\n",
    "# - Estrae gli embedding dei documenti dal modello addestrato e li riduce a 2 dimensioni per la visualizzazione (es. scatter).\n",
    "# =============================================================================\n",
    "\n",
    "# UMAP per la riduzione dimensionale interna usata da BERTopic\n",
    "umap_model = UMAP(\n",
    "    n_neighbors=15,      # equilibrio tra struttura locale/globale\n",
    "    n_components=5,      # dimensione target per la clusterizzazione\n",
    "    min_dist=0.0,        # addensa i punti; utile per separare i cluster\n",
    "    metric='cosine',     # adatta a embedding testuali\n",
    "    random_state=42      # riproducibilità\n",
    ")\n",
    "\n",
    "# Inizializza BERTopic con parametri principali dell'analisi\n",
    "topic_model = BERTopic(\n",
    "    language=\"multilingual\",          # italian is not supported    \n",
    "    calculate_probabilities=False,   # più veloce, meno memoria\n",
    "    verbose=True,                    \n",
    "    nr_topics=N_TOPICS,              # numero di topic desiderato\n",
    "    top_n_words=30,                  # n, parole rappresentative mostrate per topic\n",
    "    umap_model=umap_model            # UMAP definito sopra per ri\n",
    ")\n",
    "\n",
    "# Addestra il modello e ottiene:\n",
    "# - topics: indice di topic per ciascun documento\n",
    "topics, prob = topic_model.fit_transform(docs_unique)\n",
    "\n",
    "# Estrae gli embedding dei documenti e riduzione a 2D per plotting/visualizzazione\n",
    "embeddings = topic_model._extract_embeddings(docs_unique, method=\"document\")\n",
    "reduced_embeddings = UMAP(\n",
    "    n_neighbors=15,\n",
    "    n_components=2,\n",
    "    min_dist=0.0,\n",
    "    metric='cosine',\n",
    "    random_state=42\n",
    ").fit_transform(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af6d1100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SEZIONE 4: Salvataggio del modello e dei risultati (BERTopic)\n",
    "# -----------------------------------------------------------------------------\n",
    "# Questa sezione del notebook:\n",
    "# - Crea la cartella del modello e salva il modello BERTopic (CTFIDF + embedding model).\n",
    "# - Esporta l’assegnazione documento→topic.\n",
    "# - Esporta le informazioni riassuntive dei topic (descrizioni, conteggi, ecc.).\n",
    "# - Unisce i metadati originali dei documenti con le info dei topic e salva i risultati.\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# --- Cartella modello ---\n",
    "\n",
    "model_dir = mydir +\"BERTopicModel\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "# Modello di embedding usato, in questo caso è il default (deve corrispondere a quello del training)\n",
    "embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "# --- Salvataggio modello BERTopic ---\n",
    "# serialization=\"pytorch\": salva i pesi in formato torch\n",
    "# save_ctfidf=True: salva la matrice C-TF-IDF (utile per ricaricare topic/termini)\n",
    "# save_embedding_model=...: salva anche il modello di embedding\n",
    "topic_model.save(\n",
    "    str(model_dir),\n",
    "    serialization=\"pytorch\",\n",
    "    save_ctfidf=True,\n",
    "    save_embedding_model=embedding_model\n",
    ")\n",
    "\n",
    "# --- Esporta informazioni sui topic ---\n",
    "# get_topic_info() restituisce, tra le altre, le colonne: Topic, Count, Name\n",
    "\n",
    "topic_info = topic_model.get_topic_info()\n",
    "del topic_info['Representative_Docs']  # rimuove colonna non necessari per avere un ouput più leggero\n",
    "topic_info= topic_info.drop(df.index[0]) #la prima riga si riferisce a topic -1 (outliers non assegnati a nessuna categoria), non di interesse per successive analisi \n",
    "topic_info.to_csv(mydir +\"topics_overview.tsv\", sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76390ed5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topic_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# SEZIONE 5: Gerarchia dei topic (dendrogramma).\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Ispezione visiva delle relazioni tra i topic e i nomi dei topic. Utile anche per effettuare un sanity check dell'analisi\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m \n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Mostra il dendrogramma nel notebook \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m hierarchical_topics = \u001b[43mtopic_model\u001b[49m.hierarchical_topics(docs_unique)\n\u001b[32m     13\u001b[39m hierarchical_topics.to_csv(mydir + \u001b[33m\"\u001b[39m\u001b[33mhierarchical_topics.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m tree = topic_model.get_topic_tree(hierarchical_topics)\n",
      "\u001b[31mNameError\u001b[39m: name 'topic_model' is not defined"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SEZIONE 5: Gerarchia dei topic (dendrogramma).\n",
    "# Ispezione visiva delle relazioni tra i topic e i nomi dei topic. Utile anche per effettuare un sanity check dell'analisi\n",
    "# -----------------------------------------------------------------------------\n",
    "# Questa sezione:\n",
    "# - Genera il dendrogramma gerarchico dei topic individuati da BERTopic.\n",
    "# - Salva la stessa visualizzazione in un file HTML interattivo.\n",
    "# - Salva la struttura del dendrogramma in un file di testo.\n",
    "# =============================================================================\n",
    "\n",
    "# Mostra il dendrogramma nel notebook \n",
    "hierarchical_topics = topic_model.hierarchical_topics(docs_unique)\n",
    "hierarchical_topics.to_csv(mydir + \"hierarchical_topics.csv\")\n",
    "\n",
    "tree = topic_model.get_topic_tree(hierarchical_topics)\n",
    "f_out = open(mydir+'/topics_tree.txt','w')\n",
    "f_out.write(tree)\n",
    "\n",
    "# Crea la figura del dendrogramma (identica a quella mostrata sopra)\n",
    "fig1 = topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics)\n",
    "\n",
    "# Salva la figura come HTML interattivo nella cartella dei risultati.\n",
    "fig1.write_html(mydir + \"/Dendrogram_taxonomy.html\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_aixpa (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
